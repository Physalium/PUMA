{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\textbf{LABORATORIUM NR 7 - DRZEWA DECYZYJNE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na dzisiejszych zajęciach zapoznamy się z drzewami decyzyjnymi, czyli jedną z bardziej popularnych metod uczenia nadzorowanego. Wykorzystamy do tego zbiór danych MNIST, czyli zbiór zawierający ręcznie zapisane cyfry 0-9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najpierw pobierzemy odpowiednie biblioteki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import idx2numpy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pliki .gz wypakować (np. za pomocą darmowego programu 7-Zip) do folderu, w którym znajduje się Jupyter Notebook. Pliki po wypakowaniu powinny mieć te same nazwy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = idx2numpy.convert_from_file('train-images.idx3-ubyte')\n",
    "y_train = idx2numpy.convert_from_file('train-labels.idx1-ubyte')\n",
    "X_test = idx2numpy.convert_from_file('t10k-images.idx3-ubyte')\n",
    "y_test = idx2numpy.convert_from_file('t10k-labels.idx1-ubyte')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zobaczmy, jak wyglądają przykładowe cyfry ze zbioru MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'svg'\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(np.array(X_train[i]))\n",
    "plt.tight_layout()\n",
    "print(f'Rozmiar pojedynczego obrazka wynosi: {X_train[i].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przekonwertujmy dane na tablice Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (len(X_train), -1))\n",
    "y_train = np.reshape(y_train, (len(y_train), -1))\n",
    "X_test = np.reshape(X_test, (len(X_test), -1))\n",
    "y_test = np.reshape(y_test, (len(y_test), -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wytrenujmy klasyfikator na zbiorze MNIST, a następnie wyświetlmy mapę, która odpowie nam na pytanie, jakie piksele były najistotniejsze przy podejmowaniu decyzji przez drzewo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_classifier = tree.DecisionTreeClassifier(random_state=0)\n",
    "tree_classifier.fit(X_train, y_train)\n",
    "importances = np.reshape(tree_classifier.feature_importances_, (28, 28))\n",
    "plt.imshow(importances, cmap='hot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdźmy dokładność klasyfikacji dla zbioru treningowego i testowego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = tree_classifier.score(X_train, y_train)\n",
    "test_score = tree_classifier.score(X_test, y_test)\n",
    "test_prediction = tree_classifier.predict(X_test)\n",
    "print(f'Dokładność klasyfikacji na zbiorze treningowym wynosi: {train_score}, zaś na zbiorze testowym: {test_score}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stwórzmy teraz macierz pomyłek (ang. confusion matrix), czyli macierz, w której na przekątnej znajdują się prawidłowo zaklasyfikowane cyfry, czyli w pozycji $(i, i)$ znajduje się ilość cyfr należących do klasy $i$, które zostały przydzielone właściwie do klasy $i$. Z kolei w miejscach $(i, j)$, gdzie $i \\neq j$ znajduje się ilość cyfr należących do klasy $i$, a przydzielonych błędnie do klasy $j$. Czyli na przykład w indeksie $(0, 2)$ znajduje się liczba zer, które zostały uznane przez algorytm za dwójki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "normalize = None  # możliwości: 'true', None\n",
    "values = '.2f' if normalize == 'true' else '.4g'\n",
    "plot = plot_confusion_matrix(tree_classifier, X_test, y_test,\n",
    "                             normalize=normalize,  # wartości w skali 0-1\n",
    "                             display_labels=[i for i in range(10)], # etykiety zwiazane z cyframi\n",
    "                             values_format=values, # format wyswietlania cyfr\n",
    "                             ax=ax, # zwiekszenie rozmiarow obrazka\n",
    "                             cmap=plt.cm.Blues)\n",
    "plot.ax_.set_title('Macierz pomyłek dla zbioru testowego MNIST')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przetestujmy, jak będzie działało drzewo, gdy będziemy ustawiać mu limit głębokości. Zbyt głębokie drzewo zwiększa ryzyko przetrenowania (ang. overfitting). Wówczas spada nam dokładność klasyfikacji na zbiorze testowym, pomimo wzrostu na zbiorze treningowym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers, scores_train, scores_test = [], [], []\n",
    "depths = np.arange(2, 30, 3)  # tablica od 2 do 30, gdzie każda kolejna wartość jest większa o 3 od poprzedniej\n",
    "for depth in depths:\n",
    "    classifier = tree.DecisionTreeClassifier(random_state=0,\n",
    "                                             max_depth=depth)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    classifiers.append(classifier)\n",
    "    scores_train.append(classifier.score(X_train, y_train))\n",
    "    scores_test.append(classifier.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(scores_train)):\n",
    "    print(f'drzewo o maksymalnej głębokości {depths[i]}: dokładność na zbiorze treningowym: {scores_train[i]:.4f}, ',\n",
    "          f'dokładność na zbiorze testowym: {scores_test[i]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathbf{ZADANIE: }$ Zbiór danych Iris jest wielowymiarowym zbiorem wprowadzonym przez Ronalda Fishera. Pozwala on sklasyfikować gatunki kosaćca: Iris setosa, Iris versicolor, Iris virginica w zależności od długości i szerokości płatka, a także długości i szerokości kielicha (kwiatu). Dokonać podziału zbioru Iris na zbiór treningowy i testowy w proporcjach 70%/30%. Przeprowadzić klasyfikację z argumentem random_state=2. Za pomocą funkcji tree.plot_tree() utworzyć rysunek drzewa i zapisać je do pliku .PNG lub .PDF. Wczytanie zbioru jest najprościej możliwe w sposób następujący:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python36564bitbaseconda5417fb6948044c11ae59c9a26d782a4f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

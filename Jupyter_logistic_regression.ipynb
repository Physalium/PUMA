{
 "cells": [
  {
   "source": [
    "\\textbf{LABORATORIUM NR 3 - REGRESJA LOGISTYCZNA}"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na dzisiejszych zajęciach poznamy regresję logistyczną, która jest jednym z najprostszych klasyfikatorów. Dowiemy się również, czym są one-hot vectory, a także poznamy technikę kross-walidacji (ang. cross-validation)."
   ]
  },
  {
   "source": [
    "Zacznijmy od pobrania odpowiednich bibliotek."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wczytajmy plik z danymi. Dane te zawierają informacje o rekrutacji studentów na studia II stopnia. Pierwsza z kolumn to informacja, czy student dostał się na studia (1), czy też nie (0). Kolumna \"gre\" przedstawia liczbę punktów zdobytych w końcowym teście, kolumna \"gpa\" dotyczy średniej ocen, zaś kolumna \"rank\" odpowiada randze szkoły, w której student uczył się wcześniej. Przyjmuje wartości ze zbioru liczb: {1, 2, 3, 4}, przy czym im mniejsza wartość, tym lepsza szkoła. Parametr \\textit{skiprows} z wartością 1 dotyczy ominięcia pierwszego wiersza, który ma nagłówki kolumn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('logistyczna.csv', delimiter=',', skiprows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyrazimy ostatnią kolumnę w postaci one-hot wektorów, czyli wektorów wypełnionych zerami o rozmiarze takim jak liczba dostępnych klas, mającymi jedynkę w miejscu, które odpowiada numerkowi klasy, tzn.: klasie 1 odpowiada wektor (1, 0, 0, 0), klasie 2 (0, 1, 0, 0), klasie 3 (0, 0, 1, 0) zaś klasie 4 odpowiada wektor (0, 0, 0, 1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[2 2 0 3 3 1 0 1 2 1 3 0 0 1 0 2 3 2 1 0 2 1 3 3 1 0 0 3 1 0 3 2 2 2 0 1 0\n 2 1 2 1 1 1 2 1 2 1 3 3 2 2 3 3 1 2 2 2 2 1 3 1 3 2 2 2 1 3 0 0 0 2 3 3 1\n 3 2 2 2 0 0 3 1 1 3 2 1 1 1 0 1 1 0 1 1 1 1 3 1 1 2 2 2 3 2 1 1 0 1 2 1 3\n 3 2 0 2 2 1 1 0 2 1 1 2 2 2 3 0 3 1 3 1 1 1 2 1 2 3 2 1 0 1 3 3 2 3 2 1 2\n 0 0 0 1 1 2 2 3 1 0 1 2 1 1 1 1 1 0 3 2 2 2 2 2 2 1 3 1 1 2 2 2 2 3 1 1 3\n 1 2 1 1 1 1 2 2 3 1 1 2 3 2 3 2 1 0 3 0 2 0 0 2 1 3 1 1 2 1 2 0 0 0 1 2 2\n 0 2 1 2 1 3 1 1 3 2 1 2 0 1 1 1 3 2 1 0 2 1 0 2 1 1 2 2 3 3 1 3 3 2 1 2 1\n 1 1 1 2 2 2 2 3 2 1 2 1 2 1 0 1 1 2 0 3 1 1 2 3 3 1 3 0 3 3 3 1 1 1 0 0 2\n 0 1 1 2 1 2 1 1 2 3 0 1 1 2 2 1 2 3 3 1 1 3 3 0 2 1 3 1 2 0 1 1 1 3 2 2 0\n 2 2 0 2 3 0 2 3 2 3 1 2 2 1 1 1 1 1 2 2 1 1 0 1 0 2 2 0 0 1 1 0 2 2 2 0 1\n 1 2 0 0 1 3 1 1 2 1 1 1 1 0 1 0 1 1 1 1 1 1 2 1 2 1 2 1 1 2]\n"
     ]
    }
   ],
   "source": [
    "note = data[:, 3].astype(int)\n",
    "note = note - 1  # Przesuwamy zakres z {1, ..., 4} do {0, ..., 3}\n",
    "print(note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0. 0. 1. 0.]\n [0. 0. 1. 0.]\n [1. 0. 0. 0.]\n ...\n [0. 1. 0. 0.]\n [0. 1. 0. 0.]\n [0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "one_hot_note = np.eye(4)[note]\n",
    "print(one_hot_note)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usuńmy teraz oryginalną kolumnę odpowiadającą wartościom \"rank\" i wstawmy tam przygotowane one-hot wektory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[  0.   380.     3.61 ...   0.     1.     0.  ]\n [  1.   660.     3.67 ...   0.     1.     0.  ]\n [  1.   800.     4.   ...   0.     0.     0.  ]\n ...\n [  0.   460.     2.63 ...   1.     0.     0.  ]\n [  0.   700.     3.65 ...   1.     0.     0.  ]\n [  0.   600.     3.89 ...   0.     1.     0.  ]]\n"
     ]
    }
   ],
   "source": [
    "data = np.delete(data, 3, axis=1)\n",
    "data = np.concatenate((data, one_hot_note), axis=1)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rozdzielmy teraz dane na argumenty i wartości funkcji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:, 1:]\n",
    "y = data[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podzielmy dane na zbiór treningowy i testowy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przygotujmy funkcję do treningu regresji logistycznej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_logistic_regression(seed,\n",
    "                                epochs,\n",
    "                                X_train,\n",
    "                                y_train,\n",
    "                                X_test,\n",
    "                                y_test):\n",
    "    model = LogisticRegression(random_state=seed,\n",
    "                               solver='lbfgs',\n",
    "                               max_iter=epochs,\n",
    "                               multi_class='multinomial').fit(X_train,\n",
    "                                                              y_train)\n",
    "    train_accuracy = model.score(X_train, y_train)\n",
    "    test_accuracy = model.score(X_test, y_test)\n",
    "    print(f'''Dokladnosc klasyfikacji dla zbioru treningowego wynosi {train_accuracy},\n",
    "              zas dokladnosc klasyfikacji dla zbioru testowego wynosi {test_accuracy}.''')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dokladnosc klasyfikacji dla zbioru treningowego wynosi 0.725,\n              zas dokladnosc klasyfikacji dla zbioru testowego wynosi 0.7.\n"
     ]
    }
   ],
   "source": [
    "model = prepare_logistic_regression(1, 500, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dokonajmy teraz standaryzacji danych, czyli odejmijmy średnią i podzielmy przez odchylenie standardowe.\n",
    "\\textbf{UWAGA! Częsty błąd!} Preprocessing danych wykonujemy na danych treningowych i przygotowane w ten sposób parametry aplikujemy do zbioru testowego! Nie wykonujemy standaryzacji na całym zbiorze danych jednocześnie! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "standarization = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_standarized = standarization.transform(X_train)\n",
    "X_test_standarized = standarization.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Przykładowe dane przed standaryzacją: \n [[360.     3.     0.     0.     1.     0.  ]\n [580.     3.5    0.     1.     0.     0.  ]\n [480.     2.55   1.     0.     0.     0.  ]\n [580.     3.51   0.     1.     0.     0.  ]\n [500.     3.03   0.     0.     1.     0.  ]\n [660.     4.     0.     1.     0.     0.  ]\n [580.     3.77   0.     0.     0.     1.  ]\n [540.     3.49   1.     0.     0.     0.  ]\n [600.     3.64   0.     0.     1.     0.  ]\n [600.     3.62   0.     0.     1.     0.  ]]\nPrzykładowe dane po standaryzacji: \n [[-2.04086945 -0.97934481 -0.40824829 -0.78050971  1.50193673 -0.45485883]\n [-0.08020884  0.31559544 -0.40824829  1.28121405 -0.66580701 -0.45485883]\n [-0.97141821 -2.14479104  2.44948974 -0.78050971 -0.66580701 -0.45485883]\n [-0.08020884  0.34149424 -0.40824829  1.28121405 -0.66580701 -0.45485883]\n [-0.79317634 -0.9016484  -0.40824829 -0.78050971  1.50193673 -0.45485883]\n [ 0.63275865  1.61053569 -0.40824829  1.28121405 -0.66580701 -0.45485883]\n [-0.08020884  1.01486317 -0.40824829 -0.78050971 -0.66580701  2.19848433]\n [-0.43669259  0.28969663  2.44948974 -0.78050971 -0.66580701 -0.45485883]\n [ 0.09803303  0.67817871 -0.40824829 -0.78050971  1.50193673 -0.45485883]\n [ 0.09803303  0.6263811  -0.40824829 -0.78050971  1.50193673 -0.45485883]]\n"
     ]
    }
   ],
   "source": [
    "print(f'Przykładowe dane przed standaryzacją: \\n {X_train[:10]}')\n",
    "print(f'Przykładowe dane po standaryzacji: \\n {X_train_standarized[:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dokladnosc klasyfikacji dla zbioru treningowego wynosi 0.7214285714285714,\n              zas dokladnosc klasyfikacji dla zbioru testowego wynosi 0.7166666666666667.\n"
     ]
    }
   ],
   "source": [
    "model = prepare_logistic_regression(1, 500, X_train_standarized, y_train,\n",
    "                                    X_test_standarized, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Często stosowaną techniką w uczeniu maszynowym jest \\textbf{k-krotny sprawdzian krzyżowy} (ang. k-fold cross-validation). Zwykle stosujemy ją, gdy mamy niedobór danych, a chcemy uzyskać reprezentatywny wynik klasyfikatora. Procedura ta polega na tym, że dzielmy dane na \\textit{k} podzbiorów i trenujemy nasz klasyfikator \\textit{k} razy, za każdym razem biorąc wybrany podzbiór jako zbiór testowy, a pozostałe \\textit{k - 1} podzbiorów jako zbiór treningowy. Dla każdego $i \\in \\lbrace 1, 2, ..., k\\rbrace$ inny podzbiór znajduje się w zbiorze testowym, a zbiór treningowy stanowi połączenie pozostałych \\textit{k - 1} podzbiorów.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.7125 0.725  0.7    0.675  0.7   ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "classifier = LogisticRegression(random_state=5,\n",
    "                                solver='lbfgs',\n",
    "                                max_iter=500,\n",
    "                                multi_class='multinomial')\n",
    "scores = cross_val_score(classifier, X, y, cv=5)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Średnia dokładność klasyfikacji wynosi: 0.703, zaś odchylenie standardowe 0.017\n"
     ]
    }
   ],
   "source": [
    "print(f'Średnia dokładność klasyfikacji wynosi: {scores.mean():.3f}, zaś odchylenie standardowe {scores.std():.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}